{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generator\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 32\n",
    "batch_size_validation = 32\n",
    "\n",
    "batch_size = batch_size_training\n",
    "\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Classes\n",
    "\n",
    "class_1 = \"cat\"\n",
    "class_2 = \"dog\"\n",
    "\n",
    "# Dataset\n",
    "\n",
    "train_percent = 0.80\n",
    "val_percent = 1 - train_percent\n",
    "\n",
    "# Seeds\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# TensorBoard and MLflow Logging\n",
    "\n",
    "def create_experiment(class_1, class_2):\n",
    "    experiment_name = f\"{class_1}_{class_2}_classification\"\n",
    "    return experiment_name\n",
    "\n",
    "def create_runname(model_name):\n",
    "    run_name = datetime.now().strftime(f\"{model_name}_%Y_%m_%d__%H%M%S\")\n",
    "    return run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_dog_classification\n"
     ]
    }
   ],
   "source": [
    "experiment_name = create_experiment(class_1, class_2)\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "image_path = \"datasets/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images separated into train and validation directories successfully.\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(image_path, 'train')\n",
    "val_dir = os.path.join(image_path, 'validation')\n",
    "\n",
    "for directory in [train_dir, val_dir]:\n",
    "    os.makedirs(os.path.join(directory, class_1), exist_ok=True)\n",
    "    os.makedirs(os.path.join(directory, class_2), exist_ok=True)\n",
    "\n",
    "def move_images(source_dir, dest_dir, num_images):\n",
    "    images = os.listdir(source_dir)\n",
    "    random.shuffle(images)\n",
    "    for image in images[:num_images]:\n",
    "        src_path = os.path.join(source_dir, image)\n",
    "        dest_path = os.path.join(dest_dir, image)\n",
    "        try:\n",
    "            shutil.move(src_path, dest_path)\n",
    "        except PermissionError as e:\n",
    "            print(f\"Permission error occurred: {e}. Skipping file: {src_path}\")\n",
    "        else:\n",
    "            if dest_path.lower().endswith('.png'):\n",
    "                try:\n",
    "                    img = Image.open(dest_path)\n",
    "                    if img.mode != 'RGBA':\n",
    "                        img = img.convert('RGBA')\n",
    "                        img.save(dest_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting {dest_path}: {e}\")\n",
    "\n",
    "def split_images(image_path, train_dir, val_dir, train_percent, val_percent):\n",
    "    for category in [class_1, class_2]:\n",
    "        source_category_dir = os.path.join(image_path, category)\n",
    "        train_category_dir = os.path.join(train_dir, category)\n",
    "        val_category_dir = os.path.join(val_dir, category)\n",
    "\n",
    "        num_images = len(os.listdir(source_category_dir))\n",
    "        num_train = int(train_percent * num_images)\n",
    "        num_val = int(val_percent * num_images)\n",
    "\n",
    "        move_images(source_category_dir, train_category_dir, num_train)\n",
    "        move_images(source_category_dir, val_category_dir, num_val)\n",
    "\n",
    "split_images(image_path, train_dir, val_dir, train_percent, val_percent)\n",
    "print(\"Images separated into train and validation directories successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_resize, image_resize)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def load_pytorch_data(directory, transform):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for category in [class_1, class_2]:\n",
    "        category_path = os.path.join(directory, category)\n",
    "        label = [class_1, class_2].index(category)\n",
    "        for file in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, file)\n",
    "            if os.path.isfile(img_path):\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(label)\n",
    "    return CustomDataset(image_paths, labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MEHMET\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MEHMET\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_pytorch_data(train_dir, transform)\n",
    "val_dataset = load_pytorch_data(val_dir, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_training, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_validation, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load SqueezeNet model\n",
    "model = models.squeezenet1_0(pretrained=True)\n",
    "model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "model.num_classes = num_classes\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MEHMET\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 17.58868664331436\n",
      "Epoch 2/5, Loss: 0.6931473015785218\n",
      "Epoch 3/5, Loss: 0.6931473015785218\n",
      "Epoch 4/5, Loss: 0.6931473015785218\n",
      "Epoch 5/5, Loss: 0.6931473015785218\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "    pytorch_training_time = time.time() - start_time\n",
    "    return pytorch_training_time\n",
    "\n",
    "pytorch_training_time = train_model(model, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch training time: 3216.8956673145294 seconds\n",
      "PyTorch accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "pytorch_accuracy = correct / total\n",
    "\n",
    "print(f\"PyTorch training time: {pytorch_training_time} seconds\")\n",
    "print(f\"PyTorch accuracy: {pytorch_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'pytorch_squeezenet_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
